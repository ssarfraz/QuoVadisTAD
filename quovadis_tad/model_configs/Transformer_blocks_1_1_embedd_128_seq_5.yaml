model: Single_Transformer_block  
preprocess: "0-1"
num_blocks: 1
MHA_blocks: 1
input_sequence_length: 5
embedding_dim: 128  
dropout_rate: 0.1
positional_encoding: False
batch_size: 512
epochs: 100
optimizer: adam
learning_rate: 0.001
weight_decay: 0.0001